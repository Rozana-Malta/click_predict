{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T22:26:39.492609Z",
     "start_time": "2025-09-08T22:11:16.713300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ MODELO MELHORADO - CLICKPREDICT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =====================================================\n",
    "# CONFIGURA√á√ïES OTIMIZADAS\n",
    "# =====================================================\n",
    "CONFIG_IMPROVED = {\n",
    "    'MIN_SUPPORT': 0.0005,     # Reduzido para capturar mais padr√µes\n",
    "    'MIN_CONFIDENCE': 0.2,     # Reduzido para mais regras\n",
    "    'MIN_LIFT': 1.0,          # Reduzido para n√£o filtrar demais\n",
    "    'MAX_LEN': 2,             # Focar em pares diretos\n",
    "    'TOP_RULES': 2000,        # Mais regras para melhor cobertura\n",
    "}\n",
    "\n",
    "# =====================================================\n",
    "# FUN√á√ÉO MELHORADA DE PREPARA√á√ÉO\n",
    "# =====================================================\n",
    "def prepare_transactions_improved(df):\n",
    "    \"\"\"\n",
    "    Prepara√ß√£o focada APENAS em rotas, sem metadados\n",
    "    \"\"\"\n",
    "    print(\"\\nüìä Preparando transa√ß√µes (vers√£o melhorada)...\")\n",
    "\n",
    "    transactions = []\n",
    "\n",
    "    # Processar por cliente\n",
    "    for client_id in df['client_id'].unique():\n",
    "        client_data = df[df['client_id'] == client_id]\n",
    "        client_routes = []\n",
    "\n",
    "        for _, row in client_data.iterrows():\n",
    "            # APENAS rotas de ida\n",
    "            if pd.notna(row['origin_departure']) and pd.notna(row['destination_departure']):\n",
    "                route_dep = f\"{row['origin_departure']}_to_{row['destination_departure']}\"\n",
    "                client_routes.append(route_dep)\n",
    "\n",
    "            # APENAS rotas de volta (se existirem)\n",
    "            if not row['no_return_flag']:\n",
    "                if pd.notna(row['origin_return']) and pd.notna(row['destination_return']):\n",
    "                    route_ret = f\"{row['origin_return']}_to_{row['destination_return']}\"\n",
    "                    client_routes.append(route_ret)\n",
    "\n",
    "        # Adicionar apenas se tiver pelo menos 2 rotas\n",
    "        if len(client_routes) >= 2:\n",
    "            transactions.append(client_routes)\n",
    "\n",
    "    print(f\"   ‚Ä¢ {len(transactions)} transa√ß√µes v√°lidas criadas\")\n",
    "    print(f\"   ‚Ä¢ Transa√ß√µes com 2+ rotas: {len([t for t in transactions if len(t) >= 2])}\")\n",
    "\n",
    "    return transactions\n",
    "\n",
    "# =====================================================\n",
    "# MODELO MELHORADO\n",
    "# =====================================================\n",
    "def train_improved_model(df_train):\n",
    "    \"\"\"\n",
    "    Treina modelo com configura√ß√µes otimizadas\n",
    "    \"\"\"\n",
    "    print(\"\\nüîß Treinando modelo melhorado...\")\n",
    "\n",
    "    # Preparar transa√ß√µes (sem metadados)\n",
    "    transactions = prepare_transactions_improved(df_train)\n",
    "\n",
    "    # Converter para one-hot\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    transaction_df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    print(f\"   ‚Ä¢ Dimens√µes: {transaction_df.shape}\")\n",
    "    print(f\"   ‚Ä¢ Rotas √∫nicas: {len([c for c in transaction_df.columns if '_to_' in c])}\")\n",
    "\n",
    "    # Treinar FP-Growth\n",
    "    start = time.time()\n",
    "\n",
    "    frequent_itemsets = fpgrowth(\n",
    "        transaction_df,\n",
    "        min_support=CONFIG_IMPROVED['MIN_SUPPORT'],\n",
    "        use_colnames=True,\n",
    "        max_len=CONFIG_IMPROVED['MAX_LEN']\n",
    "    )\n",
    "\n",
    "    print(f\"   ‚Ä¢ {len(frequent_itemsets)} itemsets encontrados\")\n",
    "\n",
    "    # Gerar regras\n",
    "    if len(frequent_itemsets) > 0:\n",
    "        rules = association_rules(\n",
    "            frequent_itemsets,\n",
    "            metric=\"confidence\",\n",
    "            min_threshold=CONFIG_IMPROVED['MIN_CONFIDENCE']\n",
    "        )\n",
    "\n",
    "        # Filtrar apenas regras de rotas (n√£o metadados)\n",
    "        rules_filtered = rules[\n",
    "            rules['antecedents'].apply(lambda x: all('_to_' in str(i) for i in x)) &\n",
    "            rules['consequents'].apply(lambda x: all('_to_' in str(i) for i in x))\n",
    "        ]\n",
    "\n",
    "        # Aplicar filtro de lift\n",
    "        rules_filtered = rules_filtered[rules_filtered['lift'] >= CONFIG_IMPROVED['MIN_LIFT']]\n",
    "\n",
    "        # Ordenar e limitar\n",
    "        rules_filtered = rules_filtered.nlargest(CONFIG_IMPROVED['TOP_RULES'], 'lift')\n",
    "\n",
    "        exec_time = time.time() - start\n",
    "\n",
    "        print(f\"   ‚Ä¢ {len(rules_filtered)} regras de rotas v√°lidas\")\n",
    "        print(f\"   ‚Ä¢ Tempo: {exec_time:.2f}s\")\n",
    "\n",
    "        return rules_filtered, frequent_itemsets, transactions\n",
    "\n",
    "    return pd.DataFrame(), frequent_itemsets, transactions\n",
    "\n",
    "# =====================================================\n",
    "# AVALIA√á√ÉO MELHORADA\n",
    "# =====================================================\n",
    "def evaluate_improved(rules, df_test):\n",
    "    \"\"\"\n",
    "    Avalia√ß√£o com m√©todo melhorado\n",
    "    \"\"\"\n",
    "    print(\"\\nüìà Avaliando modelo melhorado...\")\n",
    "\n",
    "    if len(rules) == 0:\n",
    "        print(\"   ‚ùå Sem regras para avaliar\")\n",
    "        return {}\n",
    "\n",
    "    # Preparar transa√ß√µes de teste\n",
    "    test_transactions = prepare_transactions_improved(df_test)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    coverage = 0\n",
    "\n",
    "    # Criar dicion√°rio de regras para busca r√°pida\n",
    "    rules_dict = {}\n",
    "    for _, rule in rules.iterrows():\n",
    "        ant = tuple(rule['antecedents'])\n",
    "        cons = tuple(rule['consequents'])\n",
    "        if ant not in rules_dict:\n",
    "            rules_dict[ant] = []\n",
    "        rules_dict[ant].append({\n",
    "            'consequent': cons,\n",
    "            'confidence': rule['confidence'],\n",
    "            'lift': rule['lift']\n",
    "        })\n",
    "\n",
    "    # Avaliar cada transa√ß√£o\n",
    "    for transaction in test_transactions[:1000]:  # Limitar para performance\n",
    "        if len(transaction) < 2:\n",
    "            continue\n",
    "\n",
    "        # Usar primeira metade como hist√≥rico\n",
    "        split_point = len(transaction) // 2\n",
    "        history = transaction[:split_point]\n",
    "        actual = transaction[split_point:]\n",
    "\n",
    "        # Fazer previs√µes\n",
    "        predictions = []\n",
    "        for i, item in enumerate(history):\n",
    "            ant_tuple = (item,)\n",
    "            if ant_tuple in rules_dict:\n",
    "                for rule in rules_dict[ant_tuple]:\n",
    "                    predictions.extend(rule['consequent'])\n",
    "\n",
    "        if predictions:\n",
    "            coverage += 1\n",
    "            # Verificar se alguma previs√£o est√° correta\n",
    "            if any(pred in actual for pred in predictions):\n",
    "                correct += 1\n",
    "\n",
    "        total += 1\n",
    "\n",
    "    if total > 0:\n",
    "        accuracy = correct / total\n",
    "        coverage_rate = coverage / total\n",
    "\n",
    "        print(f\"   ‚Ä¢ Acur√°cia: {accuracy:.1%}\")\n",
    "        print(f\"   ‚Ä¢ Cobertura: {coverage_rate:.1%}\")\n",
    "        print(f\"   ‚Ä¢ Avaliados: {total}\")\n",
    "\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'coverage': coverage_rate,\n",
    "            'total': total,\n",
    "            'correct': correct\n",
    "        }\n",
    "\n",
    "    return {}\n",
    "\n",
    "# =====================================================\n",
    "# AN√ÅLISE DE PADR√ïES\n",
    "# =====================================================\n",
    "def analyze_patterns(rules):\n",
    "    \"\"\"\n",
    "    Analisa os padr√µes encontrados\n",
    "    \"\"\"\n",
    "    print(\"\\nüîç An√°lise de Padr√µes:\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Rotas mais frequentes como antecedente\n",
    "    all_antecedents = []\n",
    "    for ant in rules['antecedents']:\n",
    "        all_antecedents.extend(list(ant))\n",
    "\n",
    "    from collections import Counter\n",
    "    ant_counter = Counter(all_antecedents)\n",
    "\n",
    "    print(\"\\nüìç Top 5 Rotas de Origem (aparecem em regras):\")\n",
    "    for route, count in ant_counter.most_common(5):\n",
    "        if '_to_' in route:\n",
    "            origin, dest = route.split('_to_')\n",
    "            print(f\"   ‚Ä¢ {origin[:10]}... ‚Üí {dest[:10]}... ({count} regras)\")\n",
    "\n",
    "    # An√°lise de lift\n",
    "    print(f\"\\nüìä Distribui√ß√£o de Lift:\")\n",
    "    print(f\"   ‚Ä¢ Lift m√©dio: {rules['lift'].mean():.2f}\")\n",
    "    print(f\"   ‚Ä¢ Lift m√°ximo: {rules['lift'].max():.2f}\")\n",
    "    print(f\"   ‚Ä¢ Regras com lift > 10: {len(rules[rules['lift'] > 10])}\")\n",
    "    print(f\"   ‚Ä¢ Regras com lift > 5: {len(rules[rules['lift'] > 5])}\")\n",
    "\n",
    "    # An√°lise de confian√ßa\n",
    "    print(f\"\\nüìä Distribui√ß√£o de Confian√ßa:\")\n",
    "    print(f\"   ‚Ä¢ Confian√ßa m√©dia: {rules['confidence'].mean():.1%}\")\n",
    "    print(f\"   ‚Ä¢ Regras com confian√ßa > 50%: {len(rules[rules['confidence'] > 0.5])}\")\n",
    "    print(f\"   ‚Ä¢ Regras com confian√ßa > 30%: {len(rules[rules['confidence'] > 0.3])}\")\n",
    "\n",
    "# =====================================================\n",
    "# EXECUTAR AN√ÅLISE MELHORADA\n",
    "# =====================================================\n",
    "def run_improved_analysis():\n",
    "    \"\"\"\n",
    "    Executa an√°lise completa melhorada\n",
    "    \"\"\"\n",
    "    # Carregar dados\n",
    "    print(\"\\nüìÇ Carregando dados...\")\n",
    "    df = pd.read_csv('df_curado.csv')\n",
    "\n",
    "    # Usar amostra maior se dispon√≠vel\n",
    "    if len(df) > 100000:\n",
    "        print(f\"   ‚Ä¢ Dataset grande detectado: {len(df):,} registros\")\n",
    "        df = df.sample(n=100000, random_state=42)\n",
    "        print(f\"   ‚Ä¢ Usando amostra de 100k para performance\")\n",
    "\n",
    "    print(f\"   ‚Ä¢ Registros: {len(df):,}\")\n",
    "    print(f\"   ‚Ä¢ Clientes √∫nicos: {df['client_id'].nunique():,}\")\n",
    "\n",
    "    # Dividir dados\n",
    "    train_size = int(0.8 * len(df))\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "\n",
    "    print(f\"   ‚Ä¢ Treino: {len(df_train):,}\")\n",
    "    print(f\"   ‚Ä¢ Teste: {len(df_test):,}\")\n",
    "\n",
    "    # Treinar modelo melhorado\n",
    "    rules, itemsets, transactions = train_improved_model(df_train)\n",
    "\n",
    "    # Avaliar\n",
    "    metrics = evaluate_improved(rules, df_test)\n",
    "\n",
    "    # Analisar padr√µes\n",
    "    if len(rules) > 0:\n",
    "        analyze_patterns(rules)\n",
    "\n",
    "    # Mostrar top regras\n",
    "    print(\"\\nüèÜ TOP 10 REGRAS MELHORADAS:\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    for i, (_, rule) in enumerate(rules.head(10).iterrows(), 1):\n",
    "        ant = list(rule['antecedents'])[0] if rule['antecedents'] else 'N/A'\n",
    "        cons = list(rule['consequents'])[0] if rule['consequents'] else 'N/A'\n",
    "\n",
    "        # Formatar rotas\n",
    "        if '_to_' in ant and '_to_' in cons:\n",
    "            ant_parts = ant.split('_to_')\n",
    "            cons_parts = cons.split('_to_')\n",
    "\n",
    "            print(f\"\\nRegra {i}:\")\n",
    "            print(f\"  SE viaja: {ant_parts[0][:15]}... ‚Üí {ant_parts[1][:15]}...\")\n",
    "            print(f\"  ENT√ÉO: {cons_parts[0][:15]}... ‚Üí {cons_parts[1][:15]}...\")\n",
    "            print(f\"  Confian√ßa: {rule['confidence']:.1%} | Lift: {rule['lift']:.2f}\")\n",
    "\n",
    "    return rules, metrics\n",
    "\n",
    "# =====================================================\n",
    "# EXECUTAR\n",
    "# =====================================================\n",
    "if __name__ == \"__main__\":\n",
    "    rules, metrics = run_improved_analysis()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ AN√ÅLISE MELHORADA COMPLETA!\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    if metrics:\n",
    "        improvement = metrics['accuracy'] - 0.083  # Comparando com 8.3% anterior\n",
    "        if improvement > 0:\n",
    "            print(f\"üéØ Melhoria de acur√°cia: +{improvement:.1%}\")\n",
    "\n",
    "        print(f\"\"\"\n",
    "        üìä Resumo Final:\n",
    "        ‚Ä¢ Acur√°cia: {metrics['accuracy']:.1%}\n",
    "        ‚Ä¢ Cobertura: {metrics['coverage']:.1%}\n",
    "        ‚Ä¢ Regras √∫teis: {len(rules)}\n",
    "\n",
    "        üí° Recomenda√ß√µes:\n",
    "        1. Use sequ√™ncias temporais (ordem importa)\n",
    "        2. Adicione features de contexto (dia, hora, pre√ßo)\n",
    "        3. Combine com modelo de ML supervisionado\n",
    "        4. Use embeddings para rotas similares\n",
    "        \"\"\")"
   ],
   "id": "5bffc543e61bfd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ MODELO MELHORADO - CLICKPREDICT\n",
      "======================================================================\n",
      "\n",
      "üìÇ Carregando dados...\n",
      "   ‚Ä¢ Dataset grande detectado: 1,741,344 registros\n",
      "   ‚Ä¢ Usando amostra de 100k para performance\n",
      "   ‚Ä¢ Registros: 100,000\n",
      "   ‚Ä¢ Clientes √∫nicos: 78,659\n",
      "   ‚Ä¢ Treino: 80,000\n",
      "   ‚Ä¢ Teste: 20,000\n",
      "\n",
      "üîß Treinando modelo melhorado...\n",
      "\n",
      "üìä Preparando transa√ß√µes (vers√£o melhorada)...\n",
      "   ‚Ä¢ 15174 transa√ß√µes v√°lidas criadas\n",
      "   ‚Ä¢ Transa√ß√µes com 2+ rotas: 15174\n",
      "   ‚Ä¢ Dimens√µes: (15174, 6398)\n",
      "   ‚Ä¢ Rotas √∫nicas: 6398\n",
      "   ‚Ä¢ 1004 itemsets encontrados\n",
      "   ‚Ä¢ 500 regras de rotas v√°lidas\n",
      "   ‚Ä¢ Tempo: 10.35s\n",
      "\n",
      "üìà Avaliando modelo melhorado...\n",
      "\n",
      "üìä Preparando transa√ß√µes (vers√£o melhorada)...\n",
      "   ‚Ä¢ 2923 transa√ß√µes v√°lidas criadas\n",
      "   ‚Ä¢ Transa√ß√µes com 2+ rotas: 2923\n",
      "   ‚Ä¢ Acur√°cia: 42.0%\n",
      "   ‚Ä¢ Cobertura: 59.3%\n",
      "   ‚Ä¢ Avaliados: 1000\n",
      "\n",
      "üîç An√°lise de Padr√µes:\n",
      "======================================================================\n",
      "\n",
      "üìç Top 5 Rotas de Origem (aparecem em regras):\n",
      "   ‚Ä¢ fbb2a73b0b... ‚Üí 7688b6ef52... (3 regras)\n",
      "   ‚Ä¢ 6b86b273ff... ‚Üí bbb965ab0c... (2 regras)\n",
      "   ‚Ä¢ f0bc318fb8... ‚Üí 6b86b273ff... (2 regras)\n",
      "   ‚Ä¢ 7688b6ef52... ‚Üí fbb2a73b0b... (2 regras)\n",
      "   ‚Ä¢ 4652614c4d... ‚Üí 700e459d87... (2 regras)\n",
      "\n",
      "üìä Distribui√ß√£o de Lift:\n",
      "   ‚Ä¢ Lift m√©dio: 508.45\n",
      "   ‚Ä¢ Lift m√°ximo: 1686.00\n",
      "   ‚Ä¢ Regras com lift > 10: 495\n",
      "   ‚Ä¢ Regras com lift > 5: 497\n",
      "\n",
      "üìä Distribui√ß√£o de Confian√ßa:\n",
      "   ‚Ä¢ Confian√ßa m√©dia: 70.4%\n",
      "   ‚Ä¢ Regras com confian√ßa > 50%: 466\n",
      "   ‚Ä¢ Regras com confian√ßa > 30%: 495\n",
      "\n",
      "üèÜ TOP 10 REGRAS MELHORADAS:\n",
      "======================================================================\n",
      "\n",
      "Regra 1:\n",
      "  SE viaja: 81b8a03f97e8787... ‚Üí c2356069e9d1e79...\n",
      "  ENT√ÉO: c2356069e9d1e79... ‚Üí 81b8a03f97e8787...\n",
      "  Confian√ßa: 88.9% | Lift: 1686.00\n",
      "\n",
      "Regra 2:\n",
      "  SE viaja: c2356069e9d1e79... ‚Üí 81b8a03f97e8787...\n",
      "  ENT√ÉO: 81b8a03f97e8787... ‚Üí c2356069e9d1e79...\n",
      "  Confian√ßa: 100.0% | Lift: 1686.00\n",
      "\n",
      "Regra 3:\n",
      "  SE viaja: 4652614c4d8778e... ‚Üí e7866fdc6672f82...\n",
      "  ENT√ÉO: e7866fdc6672f82... ‚Üí 4652614c4d8778e...\n",
      "  Confian√ßa: 100.0% | Lift: 1517.40\n",
      "\n",
      "Regra 4:\n",
      "  SE viaja: e7866fdc6672f82... ‚Üí 4652614c4d8778e...\n",
      "  ENT√ÉO: 4652614c4d8778e... ‚Üí e7866fdc6672f82...\n",
      "  Confian√ßa: 90.0% | Lift: 1517.40\n",
      "\n",
      "Regra 5:\n",
      "  SE viaja: 2b9449f314bf931... ‚Üí 5088c1bc42f5cc6...\n",
      "  ENT√ÉO: 5088c1bc42f5cc6... ‚Üí 2b9449f314bf931...\n",
      "  Confian√ßa: 88.9% | Lift: 1498.67\n",
      "\n",
      "Regra 6:\n",
      "  SE viaja: 5088c1bc42f5cc6... ‚Üí 2b9449f314bf931...\n",
      "  ENT√ÉO: 2b9449f314bf931... ‚Üí 5088c1bc42f5cc6...\n",
      "  Confian√ßa: 88.9% | Lift: 1498.67\n",
      "\n",
      "Regra 7:\n",
      "  SE viaja: 0fbc9039145b644... ‚Üí 2b9449f314bf931...\n",
      "  ENT√ÉO: 2b9449f314bf931... ‚Üí 0fbc9039145b644...\n",
      "  Confian√ßa: 72.7% | Lift: 1379.45\n",
      "\n",
      "Regra 8:\n",
      "  SE viaja: 2b9449f314bf931... ‚Üí 0fbc9039145b644...\n",
      "  ENT√ÉO: 0fbc9039145b644... ‚Üí 2b9449f314bf931...\n",
      "  Confian√ßa: 100.0% | Lift: 1379.45\n",
      "\n",
      "Regra 9:\n",
      "  SE viaja: 8111eb155622954... ‚Üí fc72c98a6c2916c...\n",
      "  ENT√ÉO: fc72c98a6c2916c... ‚Üí 8111eb155622954...\n",
      "  Confian√ßa: 66.7% | Lift: 1264.50\n",
      "\n",
      "Regra 10:\n",
      "  SE viaja: fc72c98a6c2916c... ‚Üí 8111eb155622954...\n",
      "  ENT√ÉO: 8111eb155622954... ‚Üí fc72c98a6c2916c...\n",
      "  Confian√ßa: 100.0% | Lift: 1264.50\n",
      "\n",
      "======================================================================\n",
      "‚úÖ AN√ÅLISE MELHORADA COMPLETA!\n",
      "======================================================================\n",
      "üéØ Melhoria de acur√°cia: +33.7%\n",
      "\n",
      "        üìä Resumo Final:\n",
      "        ‚Ä¢ Acur√°cia: 42.0%\n",
      "        ‚Ä¢ Cobertura: 59.3%\n",
      "        ‚Ä¢ Regras √∫teis: 500\n",
      "\n",
      "        üí° Recomenda√ß√µes:\n",
      "        1. Use sequ√™ncias temporais (ordem importa)\n",
      "        2. Adicione features de contexto (dia, hora, pre√ßo)\n",
      "        3. Combine com modelo de ML supervisionado\n",
      "        4. Use embeddings para rotas similares\n",
      "        \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T22:48:20.227472Z",
     "start_time": "2025-09-08T22:48:17.530477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ====== 1) SALVAR O MODELO (pickle + resumo JSON) ======\n",
    "import pickle, json\n",
    "from datetime import datetime\n",
    "\n",
    "def salvar_modelo_treinado(rules, metrics, caminho_modelo='modelo_fpgrowth.pkl', caminho_resumo='modelo_resumo.json'):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üíæ SALVANDO MODELO TREINADO\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    modelo_completo = {\n",
    "        'rules': rules,                  # DataFrame com colunas: antecedents, consequents, confidence, lift\n",
    "        'metrics': metrics or {},        # dict: ex. {'accuracy': 0.23, 'coverage': 0.51}\n",
    "        'config': {\n",
    "            'MIN_SUPPORT': 0.0005,\n",
    "            'MIN_CONFIDENCE': 0.2,\n",
    "            'MIN_LIFT': 1.0,\n",
    "            'MAX_LEN': 2,\n",
    "            'TOP_RULES': 2000\n",
    "        },\n",
    "        'training_date': datetime.now().isoformat(),\n",
    "        'version': '2.0'\n",
    "    }\n",
    "\n",
    "    with open(caminho_modelo, 'wb') as f:\n",
    "        pickle.dump(modelo_completo, f)\n",
    "\n",
    "    resumo = {\n",
    "        'data_treino': modelo_completo['training_date'],\n",
    "        'total_regras': int(len(rules)) if rules is not None else 0,\n",
    "        'acuracia': float((metrics or {}).get('accuracy', 0.0)),\n",
    "        'cobertura': float((metrics or {}).get('coverage', 0.0)),\n",
    "    }\n",
    "    with open(caminho_resumo, 'w') as f:\n",
    "        json.dump(resumo, f, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Modelo salvo em: {caminho_modelo}\")\n",
    "    print(f\"‚úÖ Resumo salvo em: {caminho_resumo}\")\n",
    "    print(\"\\nüìä Estat√≠sticas do modelo:\")\n",
    "    print(f\"   ‚Ä¢ Regras: {resumo['total_regras']}\")\n",
    "    print(f\"   ‚Ä¢ Acur√°cia: {resumo['acuracia']:.1%}\")\n",
    "    print(f\"   ‚Ä¢ Cobertura: {resumo['cobertura']:.1%}\")\n",
    "    return modelo_completo\n",
    "\n",
    "# üëâ Salva imediatamente (rules/metrics j√° devem existir no ambiente)\n",
    "_ = salvar_modelo_treinado(rules, metrics)\n",
    "\n",
    "\n",
    "# ====== 2) CARREGAR E USAR O MODELO PARA PREVER (CSV OU DF) ======\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class PreditorRotas:\n",
    "    \"\"\"\n",
    "    Preditor de rotas baseado em regras de associa√ß√£o (FP-Growth).\n",
    "    O pickle deve conter a chave 'rules' (DataFrame) com colunas:\n",
    "    ['antecedents','consequents','confidence','lift'].\n",
    "    \"\"\"\n",
    "    def __init__(self, caminho_modelo: str = \"modelo_fpgrowth.pkl\"):\n",
    "        print(\"üìÇ Carregando modelo...\")\n",
    "        if not os.path.exists(caminho_modelo):\n",
    "            raise FileNotFoundError(f\"Arquivo de modelo n√£o encontrado: {caminho_modelo}\")\n",
    "        with open(caminho_modelo, \"rb\") as f:\n",
    "            self.modelo = pickle.load(f)\n",
    "        if \"rules\" not in self.modelo:\n",
    "            raise KeyError(\"O pickle n√£o cont√©m a chave 'rules'.\")\n",
    "        self.rules = self.modelo[\"rules\"]\n",
    "        print(f\"‚úÖ {len(self.rules)} regras carregadas\")\n",
    "\n",
    "        # √çndice: (antecedente,) -> lista de {dest, conf, lift}\n",
    "        self.indice: Dict[Any, List[Dict[str, Any]]] = {}\n",
    "        for _, rule in self.rules.iterrows():\n",
    "            ant_list = self._to_list(rule[\"antecedents\"])\n",
    "            cons_list = self._to_list(rule[\"consequents\"])\n",
    "            ant_key = tuple(ant_list)\n",
    "            self.indice.setdefault(ant_key, []).append({\n",
    "                \"dest\": cons_list,\n",
    "                \"conf\": float(rule[\"confidence\"]),\n",
    "                \"lift\": float(rule[\"lift\"]),\n",
    "            })\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_list(x):\n",
    "        if isinstance(x, (set, frozenset, tuple, list)):\n",
    "            return list(x)\n",
    "        return [x]\n",
    "\n",
    "    def processar_csv(self, arquivo_csv: str, sep: str = \",\", encoding: str = \"utf-8\", salvar: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Espera CSV com colunas:\n",
    "          - client_id\n",
    "          - origin_departure, destination_departure\n",
    "          - origin_return, destination_return\n",
    "          - no_return_flag  (True = sem volta / False = tem volta)\n",
    "        \"\"\"\n",
    "        print(f\"\\nüìä Processando {arquivo_csv}...\")\n",
    "        if not os.path.exists(arquivo_csv):\n",
    "            raise FileNotFoundError(f\"CSV n√£o encontrado: {arquivo_csv}\")\n",
    "        df = pd.read_csv(arquivo_csv, sep=sep, encoding=encoding)\n",
    "        df_result = self.processar_dataframe(df)\n",
    "        if salvar:\n",
    "            saida = arquivo_csv.replace(\".csv\", \"_previsoes.csv\")\n",
    "            df_result.to_csv(saida, index=False)\n",
    "            print(f\"‚úÖ Salvo em {saida}\")\n",
    "        print(\"\\nüìã Primeiras previs√µes:\")\n",
    "        print(df_result.head(10))\n",
    "        return df_result\n",
    "\n",
    "    def processar_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        colunas_esperadas = [\n",
    "            \"client_id\",\n",
    "            \"origin_departure\", \"destination_departure\",\n",
    "            \"origin_return\", \"destination_return\",\n",
    "            \"no_return_flag\",\n",
    "        ]\n",
    "        faltando = [c for c in colunas_esperadas if c not in df.columns]\n",
    "        if faltando:\n",
    "            raise KeyError(\n",
    "                \"Colunas faltando no DataFrame: \"\n",
    "                + \", \".join(faltando)\n",
    "                + \"\\nüí° Ajuste seu CSV/DF para conter essas colunas.\"\n",
    "            )\n",
    "\n",
    "        resultados: List[Dict[str, Any]] = []\n",
    "        for client_id in df[\"client_id\"].dropna().unique():\n",
    "            client_df = df[df[\"client_id\"] == client_id]\n",
    "\n",
    "            # Extrair rotas do cliente\n",
    "            rotas: List[str] = []\n",
    "            for _, row in client_df.iterrows():\n",
    "                # ida\n",
    "                if pd.notna(row[\"origin_departure\"]) and pd.notna(row[\"destination_departure\"]):\n",
    "                    rotas.append(f\"{row['origin_departure']}_to_{row['destination_departure']}\")\n",
    "                # volta (se houver)\n",
    "                no_return = row.get(\"no_return_flag\", True)\n",
    "                if not bool(no_return):\n",
    "                    if pd.notna(row.get(\"origin_return\")) and pd.notna(row.get(\"destination_return\")):\n",
    "                        rotas.append(f\"{row['origin_return']}_to_{row['destination_return']}\")\n",
    "\n",
    "            # Prever pr√≥ximas rotas (top-5)\n",
    "            previsoes = self.prever(rotas)\n",
    "            for i, p in enumerate(previsoes[:5], 1):\n",
    "                resultados.append({\n",
    "                    \"cliente\": client_id,\n",
    "                    \"rank\": i,\n",
    "                    \"rota\": p[\"rota\"],\n",
    "                    \"confianca\": f\"{p['conf']:.1%}\",\n",
    "                    \"lift\": f\"{p['lift']:.1f}\",\n",
    "                })\n",
    "\n",
    "        return pd.DataFrame(resultados)\n",
    "\n",
    "    def prever(self, rotas_cliente: List[str]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Recebe lista de rotas j√° realizadas pelo cliente (strings 'A_to_B')\n",
    "        e retorna lista √∫nica ordenada por (conf * lift).\n",
    "        \"\"\"\n",
    "        previsoes: List[Dict[str, Any]] = []\n",
    "        for rota in rotas_cliente:\n",
    "            chave = (rota,)\n",
    "            if chave in self.indice:\n",
    "                for regra in self.indice[chave]:\n",
    "                    for dest in regra[\"dest\"]:\n",
    "                        if dest not in rotas_cliente:\n",
    "                            previsoes.append({\n",
    "                                \"rota\": dest,\n",
    "                                \"conf\": regra[\"conf\"],\n",
    "                                \"lift\": regra[\"lift\"],\n",
    "                            })\n",
    "\n",
    "        vistos = set()\n",
    "        unicos: List[Dict[str, Any]] = []\n",
    "        for p in sorted(previsoes, key=lambda x: x[\"conf\"] * x[\"lift\"], reverse=True):\n",
    "            if p[\"rota\"] not in vistos:\n",
    "                vistos.add(p[\"rota\"])\n",
    "                unicos.append(p)\n",
    "        return unicos\n",
    "\n",
    "\n",
    "# ====== 3) EXEMPLOS DE USO (ESCOLHA UM) ======\n",
    "# (A) Usar um CSV j√° salvo em disco:\n",
    "CSV_ENTRADA = \"df_curado_head5000.csv\"   # <-- troque pelo seu arquivo .csv\n",
    "p = PreditorRotas(\"modelo_fpgrowth.pkl\")\n",
    "df_pred = p.processar_csv(CSV_ENTRADA)   # se seu CSV for ; e latin-1: p.processar_csv(CSV_ENTRADA, sep=\";\", encoding=\"latin-1\")\n",
    "\n",
    "# (B) OU, se voc√™ j√° tem um DataFrame em mem√≥ria:\n",
    "# df = pd.read_csv(CSV_ENTRADA)         # ou seu DF j√° carregado\n",
    "# df_pred = p.processar_dataframe(df)\n",
    "\n",
    "# Visualizar as primeiras linhas\n",
    "df_pred.head(10)\n"
   ],
   "id": "a58fe8771f95351e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üíæ SALVANDO MODELO TREINADO\n",
      "======================================================================\n",
      "‚úÖ Modelo salvo em: modelo_fpgrowth.pkl\n",
      "‚úÖ Resumo salvo em: modelo_resumo.json\n",
      "\n",
      "üìä Estat√≠sticas do modelo:\n",
      "   ‚Ä¢ Regras: 500\n",
      "   ‚Ä¢ Acur√°cia: 42.0%\n",
      "   ‚Ä¢ Cobertura: 59.3%\n",
      "üìÇ Carregando modelo...\n",
      "‚úÖ 500 regras carregadas\n",
      "\n",
      "üìä Processando df_curado_head5000.csv...\n",
      "‚úÖ Salvo em df_curado_head5000_previsoes.csv\n",
      "\n",
      "üìã Primeiras previs√µes:\n",
      "                                             cliente  rank  \\\n",
      "0  3467ec081e2421e72c96e7203b929d21927fd00b6b5f28...     1   \n",
      "1  3467ec081e2421e72c96e7203b929d21927fd00b6b5f28...     2   \n",
      "2  ceea0de820a6379f2c4215bddaec66c33994b304607e56...     1   \n",
      "3  e15109b0b8e9f6f1554e560837eb55543f035f91d8be4f...     1   \n",
      "4  ec66b05934a8d00f661257ea91874241fccb4fb128028d...     1   \n",
      "5  cf95d567cc38355ed310d70e5d43fb4af67a0373c7282d...     1   \n",
      "6  2bda00506cf67ae2828006c8131bd215ada4943dd1738d...     1   \n",
      "7  3265420405fa6251960db35d01bcdc0af0eda2dfaf5b96...     1   \n",
      "8  3265420405fa6251960db35d01bcdc0af0eda2dfaf5b96...     2   \n",
      "9  7c371df88bf42570a41524acf6d0db9f4ec1f0631df16c...     1   \n",
      "\n",
      "                                                rota confianca   lift  \n",
      "0  8c1f1046219ddd216a023f792356ddf127fce372a72ec9...     83.3%  702.5  \n",
      "1  7688b6ef52555962d008fff894223582c484517cea7da4...     71.7%   14.2  \n",
      "2  23765fc69c4e3c0b10f5d15471dc2245e2a19af16b513f...     63.0%  113.7  \n",
      "3  be47addbcb8f60566a3d7fd5a36f8195798e2848b36819...     65.0%  580.2  \n",
      "4  7688b6ef52555962d008fff894223582c484517cea7da4...     61.1%  264.9  \n",
      "5  23765fc69c4e3c0b10f5d15471dc2245e2a19af16b513f...     63.0%  113.7  \n",
      "6  093434a3ee9e0a010bb2c2aae06c2614dd24894062a1ca...     48.7%  224.0  \n",
      "7  6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d...     61.9%  213.5  \n",
      "8  5c06e46c5e47cfacad16ce1e37f17c09fdbc7072c56761...     51.1%  198.7  \n",
      "9  5c06e46c5e47cfacad16ce1e37f17c09fdbc7072c56761...     51.1%  198.7  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                             cliente  rank  \\\n",
       "0  3467ec081e2421e72c96e7203b929d21927fd00b6b5f28...     1   \n",
       "1  3467ec081e2421e72c96e7203b929d21927fd00b6b5f28...     2   \n",
       "2  ceea0de820a6379f2c4215bddaec66c33994b304607e56...     1   \n",
       "3  e15109b0b8e9f6f1554e560837eb55543f035f91d8be4f...     1   \n",
       "4  ec66b05934a8d00f661257ea91874241fccb4fb128028d...     1   \n",
       "5  cf95d567cc38355ed310d70e5d43fb4af67a0373c7282d...     1   \n",
       "6  2bda00506cf67ae2828006c8131bd215ada4943dd1738d...     1   \n",
       "7  3265420405fa6251960db35d01bcdc0af0eda2dfaf5b96...     1   \n",
       "8  3265420405fa6251960db35d01bcdc0af0eda2dfaf5b96...     2   \n",
       "9  7c371df88bf42570a41524acf6d0db9f4ec1f0631df16c...     1   \n",
       "\n",
       "                                                rota confianca   lift  \n",
       "0  8c1f1046219ddd216a023f792356ddf127fce372a72ec9...     83.3%  702.5  \n",
       "1  7688b6ef52555962d008fff894223582c484517cea7da4...     71.7%   14.2  \n",
       "2  23765fc69c4e3c0b10f5d15471dc2245e2a19af16b513f...     63.0%  113.7  \n",
       "3  be47addbcb8f60566a3d7fd5a36f8195798e2848b36819...     65.0%  580.2  \n",
       "4  7688b6ef52555962d008fff894223582c484517cea7da4...     61.1%  264.9  \n",
       "5  23765fc69c4e3c0b10f5d15471dc2245e2a19af16b513f...     63.0%  113.7  \n",
       "6  093434a3ee9e0a010bb2c2aae06c2614dd24894062a1ca...     48.7%  224.0  \n",
       "7  6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d...     61.9%  213.5  \n",
       "8  5c06e46c5e47cfacad16ce1e37f17c09fdbc7072c56761...     51.1%  198.7  \n",
       "9  5c06e46c5e47cfacad16ce1e37f17c09fdbc7072c56761...     51.1%  198.7  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cliente</th>\n",
       "      <th>rank</th>\n",
       "      <th>rota</th>\n",
       "      <th>confianca</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3467ec081e2421e72c96e7203b929d21927fd00b6b5f28...</td>\n",
       "      <td>1</td>\n",
       "      <td>8c1f1046219ddd216a023f792356ddf127fce372a72ec9...</td>\n",
       "      <td>83.3%</td>\n",
       "      <td>702.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3467ec081e2421e72c96e7203b929d21927fd00b6b5f28...</td>\n",
       "      <td>2</td>\n",
       "      <td>7688b6ef52555962d008fff894223582c484517cea7da4...</td>\n",
       "      <td>71.7%</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ceea0de820a6379f2c4215bddaec66c33994b304607e56...</td>\n",
       "      <td>1</td>\n",
       "      <td>23765fc69c4e3c0b10f5d15471dc2245e2a19af16b513f...</td>\n",
       "      <td>63.0%</td>\n",
       "      <td>113.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e15109b0b8e9f6f1554e560837eb55543f035f91d8be4f...</td>\n",
       "      <td>1</td>\n",
       "      <td>be47addbcb8f60566a3d7fd5a36f8195798e2848b36819...</td>\n",
       "      <td>65.0%</td>\n",
       "      <td>580.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ec66b05934a8d00f661257ea91874241fccb4fb128028d...</td>\n",
       "      <td>1</td>\n",
       "      <td>7688b6ef52555962d008fff894223582c484517cea7da4...</td>\n",
       "      <td>61.1%</td>\n",
       "      <td>264.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cf95d567cc38355ed310d70e5d43fb4af67a0373c7282d...</td>\n",
       "      <td>1</td>\n",
       "      <td>23765fc69c4e3c0b10f5d15471dc2245e2a19af16b513f...</td>\n",
       "      <td>63.0%</td>\n",
       "      <td>113.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2bda00506cf67ae2828006c8131bd215ada4943dd1738d...</td>\n",
       "      <td>1</td>\n",
       "      <td>093434a3ee9e0a010bb2c2aae06c2614dd24894062a1ca...</td>\n",
       "      <td>48.7%</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3265420405fa6251960db35d01bcdc0af0eda2dfaf5b96...</td>\n",
       "      <td>1</td>\n",
       "      <td>6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d...</td>\n",
       "      <td>61.9%</td>\n",
       "      <td>213.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3265420405fa6251960db35d01bcdc0af0eda2dfaf5b96...</td>\n",
       "      <td>2</td>\n",
       "      <td>5c06e46c5e47cfacad16ce1e37f17c09fdbc7072c56761...</td>\n",
       "      <td>51.1%</td>\n",
       "      <td>198.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7c371df88bf42570a41524acf6d0db9f4ec1f0631df16c...</td>\n",
       "      <td>1</td>\n",
       "      <td>5c06e46c5e47cfacad16ce1e37f17c09fdbc7072c56761...</td>\n",
       "      <td>51.1%</td>\n",
       "      <td>198.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
