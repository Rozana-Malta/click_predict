# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EX5IqZRI0SC9pLz-YGAuD0DEnItVzbKQ
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

# --- BASE DE TREINO ---
caminho_arqv_base_click = 'df_t.csv'
# LENDO O ARQUIVO EM UM DATAFRAME
df_train = pd.read_csv(caminho_arqv_base_click, delimiter=";")
# removendo qualquer espaço
df_train.columns = df_train.columns.str.strip()
# criando a coluna de data/hora
df_train['purchase_datetime'] = pd.to_datetime(
    df_train['data'] + ' ' + df_train['time_purchase'], errors='coerce'
)
# removendo anos que influenciam queda no nosso modelo de previsão
df_train = df_train[~df_train['purchase_datetime'].dt.year.isin([2014,2013,2015,2016,2017,2018,2019,2020,2021])]

# --- Pré-processamento e Engenharia de Variáveis para TREINO ---

# transformando a coluna total_value em float
df_train['total_value'] = df_train['total_value'].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).astype(float)
# transformando a coluna purchase_datetime em datetime
df_train['purchase_datetime'] = pd.to_datetime(df_train['purchase_datetime'], format='mixed')
# ordenando o df por client_id e purchase_datetime
df_train.sort_values(by=['client_id', 'purchase_datetime'], inplace=True)
# calculando a quantidade de dias até a proxima compra dos nossos clientes
df_train['time_to_next_purchase'] = df_train.groupby('client_id')['purchase_datetime'].diff().shift(-1).dt.days
# calculando para cada grupo de cliente a quantidade de dias desde a utlima compra
df_train['recency'] = df_train.groupby('client_id')['purchase_datetime'].diff().dt.days
# filtrando nossa coluna time_to_next_purchase para verificar somente clientes previsto para compra dentro de 30 dias
df_train.drop(df_train[df_train['time_to_next_purchase'] > 30].index, inplace=True)
# remove do dataframe as linhas aonde a coluna time_to_next_purchase for nula
df_train.dropna(subset=['time_to_next_purchase'], inplace=True)
# criando a coluna de frequençia de compra por cliente
df_train['frequency'] = df_train.groupby('client_id')['order_id'].transform('count')
# criando a coluna de média de compra de cada cliente
df_train['average_value'] = df_train.groupby('client_id')['total_value'].transform('mean')

# --- TREINAMENTO DO MODELO COM GRID SEARCH ---
# definindo as features que serão ultilizadas
features = ['frequency', 'recency', 'average_value', 'total_value']
# definindo a target que será prevista
target = 'time_to_next_purchase'
# definindo eixo X
X = df_train[features]
# definindo eixo y
y = df_train[target]
# Criando conjunto de dados para teste e treinamento do modelo
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definindo o modelo base
lgbm_model = LGBMRegressor(random_state=42)

# Definindo o espaço de parâmetros a ser explorado
param_grid = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.05, 0.1, 0.2],
    'max_depth': [5, 10, 15]
}

# Configurando o Grid Search com validação cruzada
grid_search = GridSearchCV(estimator=lgbm_model, param_grid=param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=1)

# Treinando o Grid Search nos dados de treino
grid_search.fit(X_train, y_train)

# Obtendo o melhor modelo e os melhores parâmetros
best_model = grid_search.best_estimator_
print("Melhores parâmetros encontrados pelo Grid Search: ")
print(grid_search.best_params_)

# --- BASE DE TESTE ---
df_predicao = pd.read_csv("df_curado_head5000.csv", delimiter=";")
# removendo espaços em brancos
df_predicao.columns = df_predicao.columns.str.strip()

# --- Pré-processamento e Engenharia de Variáveis para PREVISÃO ---
# transformando a coluna de total_value em float
df_predicao['total_value'] = df_predicao['total_value'].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).str.replace('R$', '', regex=False).str.strip().astype(float)
# transformando a coluna purchase_datetime em datetime
df_predicao['purchase_datetime'] = pd.to_datetime(df_predicao['purchase_datetime'], format='mixed')
# ordenando o df por cliente e data
df_predicao.sort_values(by=['client_id', 'purchase_datetime'], inplace=True)
# calculando a quantidade de dias desde a ultima compra
df_predicao['recency'] = df_predicao.groupby('client_id')['purchase_datetime'].diff().dt.days
# calculando a frequençia de compra por cliente
df_predicao['frequency'] = df_predicao.groupby('client_id')['order_id'].transform('count')
# calculando a média de compra por cliente
df_predicao['average_value'] = df_predicao.groupby('client_id')['total_value'].transform('mean')

# Selecionar as features da base de predição DEPOIS de todo o pré-processamento
X_pred = df_predicao[features] # adicionando as features ao EIXO X
# verificando se existe valores zerados dentro da coluna recency
X_pred.loc[:, 'recency'] = X_pred['recency'].fillna(0)

# Fazer a previsão com o modelo OTIMIZADO (best_model)
predictions_test = best_model.predict(X_test) # realizando a previsão da base de teste com melhor parametro calculado
predictions_predicao = best_model.predict(X_pred) # realizando a previsão da base de real com melhor parametro calculado

# margem de erro definidade de acordo com o resultado da metrica de MAE(Erro médio Absoluto)
threshold = 7

# Calcula a diferença absoluta entre as previsões e os valores reais (no conjunto de teste)
errors = np.abs(predictions_test - y_test)

# Conta quantas previsões estão dentro da margem de acerto
correct_predictions_count = np.sum(errors <= threshold)

# Conta quantidade de clientes previsto
total_predictions_count = len(y_test)
# Calculando a porcentagem de acertos
accuracy_percentage = (correct_predictions_count / total_predictions_count) * 100
#calculando a MAE(Erro médio Absoluto)
mae = mean_absolute_error(y_test, predictions_test)
# calculando a MSE(Erro Quadrático Médio)
mse = mean_squared_error(y_test, predictions_test)
print(f"\nErro Absoluto Médio (MAE) no conjunto de teste: {mae:.2f} dias")
print(f"Erro Quadrático Médio (MSE) no conjunto de teste: {mse:.2f}")
print(f"Porcentagem de 'acertos' (margem de {threshold} dias) no conjunto de teste: {accuracy_percentage:.2f}%")

# --- Salvar os resultados em um arquivo CSV ---
df_predicao['predicted_time_to_next_purchase'] = predictions_predicao
df_saida = df_predicao[['client_id', 'purchase_datetime', 'predicted_time_to_next_purchase']].copy()
df_saida['predicted_time_to_next_purchase'] = df_saida['predicted_time_to_next_purchase'].fillna(-1).astype(int)
predicted_timedelta = pd.to_timedelta(df_saida['predicted_time_to_next_purchase'], unit='D')
df_saida['predicted_next_purchase_date'] = df_saida['purchase_datetime'] + predicted_timedelta
df_saida.to_csv('previsoes_proxima_compra_com_valor.csv', index=False)

import plotly.express as px

fig = px.imshow(
    df_train[features].corr(),
    text_auto=True,
    color_continuous_scale='RdBu_r',
    title='Correlação entre Features'
)
fig.show()


# print("\nPrevisões com valor salvas com sucesso no arquivo 'previsoes_proxima_compra_com_valor.csv'!")
# print("\nPrimeiras 5 linhas do arquivo de saída:")
# display(df_saida.head())